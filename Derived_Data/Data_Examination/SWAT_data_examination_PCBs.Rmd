---
title: "Review of Maine DEP EGAD Mussel Tissue Toxics Parameters"
subtitle: "Identifying and Classifying Parameters"
author: "Curtis C. Bohlen, Casco Bay Estuary Partnership"
date: "9/18/2020"
output:
  github_document:
    toc: true
    toc_depth: 2
    fig_width: 7
    fig_height: 5
---

<img
  src="https://www.cascobayestuary.org/wp-content/uploads/2014/04/logo_sm.jpg"
  style="position:absolute;top:10px;right:50px;" />

# Introduction
Maine's Department of Environmental Protection (DEP) maintains a large database
of environmental data called "EGAD".  Citizens can request data from the
database through DEP staff.

CBEP requested data from DEP on levels of toxic contaminants in shellfish
tissue samples from Casco Bay. The result is a large (> 100,000 line) excel
spreadsheet containing data from about 40 sampling dates from 20 locations, over
a period of more than 15 years.

Unfortunately, the data delivery contains limited metadata, so it takes some
effort to understand the data format and analyze it correctly.

In this notebook we review the parameters identified in the data and assign them
to groups to facilitate analysis.  We also check on a number of technical
matters dealing with how various totals were calculated.  These include:
*  Figuring out which compounds were included in various totals
*  Determining how NOn-detects were included in totals

# Load Libraries
```{r load_libraries}
library(tidyverse)
library(readxl)
library(htmltools)  # used by knitr called here only to avoid startup text later
library(knitr)
```

# Load Data
## Establish Folder Reference
```{r folder_refs}
auntfldnm <- 'Original_Data'
parent   <- dirname(getwd())
grandparent <- dirname(parent)
aunt  <- file.path(grandparent,auntfldnm)
fn <- 'CascoBaySWATtissue_Bohlen.xlsx'
```

## Copy Data
This is a larger data file that takes some time to load.  Getting the column
types right dramatically improves load speed. Much of the data is qualitative,
and can't be handled in R.
```{r copy_data}
SWAT_data <- read_excel(file.path(aunt, fn), 
    sheet = "Mussels Data", col_types = c("numeric", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "date", "text", "text", 
        "text", "date", "text", "numeric", 
        "text", "text", "text", "text", 
        "text", "numeric", "numeric", "text", 
        "text", "text", "text", "text", 
        "text", "numeric", "text", 
        "text", "text", "text", "text", 
        "text", "text", "text"))
before <- nrow(SWAT_data)
```

## Remove duplicates
Many samples -- nearly 20% -- are members of a group of duplicates.  We can
think of no valid reason why two records should be exact duplicates in this
setting, so we remove all duplicates using the unique() function.
```{r remove_duplicates}
SWAT_data <- unique(SWAT_data)
```

## Simplify Data and Add Unique Sample Codes
This logic was developed in "SWAT_data examination_UNIQUE.Rmd".
```{r}
SWAT_simplified <- SWAT_data %>%
  # Eliminate uninformative identifiers
  select    (-`SAMPLE TYPE`, -`SAMPLE POINT TYPE`, -`SAMPLE LOCATION`,
             -`RESULT TYPE`, -`PARAMETER_QUALIFIER`, -`PARAMETER FILTERED`,
             -`SAMPLE FILTER`, -`DEPTH`, -`DEPTH UNITS`,
             -TREATMENT, -`METER_CALIBRATED`) %>%
  
  # Eliminate data we will not analyze
  select    (-SITE_DESCRIPTION, -ANALYSIS_DATE,
             -`QC TYPE`, -SAMPLED_BY, -`UNITS DESCRIPTION`,
             -`SAMPLE COMMENT`, -`LAB COMMENT`, -`VALIDATION COMMENT`) %>%
  
  # Create Site Code and Site Name
  mutate    (SiteCode =  sub('.* - ','', `EGAD_SITE_NAME`), 
             Site     =  sub(' - .*','', `EGAD_SITE_NAME`)) %>%
  select    (-EGAD_SITE_NAME) %>%
  
  # Create Year Time Stamp and (Draft 1) Unique Sample ID
  mutate    (Year  = as.numeric(format(SAMPLE_DATE, '%Y')),
             sample_id = gsub(" ", "_", SAMPLE_ID)) %>%
  group_by  (Year) %>%
  mutate    (tag = as.numeric(factor(SAMPLE_DATE))) %>%
  ungroup   ()  %>%
  mutate    (Code = paste(sample_id, Year, tag, sep = '_')) %>%
  select    (-sample_id, -tag) %>%
  select    (`SITE SEQ`, SiteCode, Site, Year, SAMPLE_DATE,
              SAMPLE_ID, Code, everything())
```

## Add Class to the Working Simplified Data
We can then read in the resulting Excel File to provide groupings...
```{r}
Parameter_List <- read_excel(file.path(parent,"Parameter List.xlsx"), 
    sheet = "Parameter List") %>%
  mutate(Class = factor(Class)) %>%
  arrange(Class, PARAMETER)

SWAT_simplified <- SWAT_simplified %>% 
  mutate(Class = Parameter_List$Class[match(PARAMETER, Parameter_List$PARAMETER)])
```

#  PCB Nomenclature
Many of the PCBs chemical names and the PCB numerical designations turn up in
the same number of composite samples, which suggests they are reported on the
same samples.  I wonder if these represent duplicate data.


## Examining CAS numbers
Lets see how many times we have duplicate values with the same CAS number.

```{r}
SWAT_simplified %>% 
 # filter(`WEIGHT BASIS` == 'LIP') %>%
  group_by(CAS_NO) %>%
  filter(grepl('PCB', Class)) %>%
  summarize(nnames = length(unique(PARAMETER)),
            name = first (PARAMETER),
            .groups = 'drop') %>%
  arrange(name)
```
So we have no duplicates.

All the PCBs listed by PCB number are in fact mixtures of PCBs. So technically,
they are NOT individual PCBs. The question is, how are they used?  And
especially, how are the total PCBs calculated?

WE zero in on a few parameters that either emphasize PCB names (mixtures) or
chemical nomenclature (individual compounds).
```{r}
SWAT_simplified %>% 
  select(Code, `TEST METHOD`, Year, ANALYSIS_LAB_SAMPLE_ID, `WEIGHT BASIS`,
         PARAMETER, CONCENTRATION, Class) %>%
  filter (`WEIGHT BASIS` == 'WET') %>%
  filter(grepl('PCB', Class)) %>%
  pivot_wider(names_from = PARAMETER, values_from = CONCENTRATION) %>%
  select(-ANALYSIS_LAB_SAMPLE_ID, -Class, -Code) %>%
  select(sort(current_vars())) %>%
  select(`TEST METHOD`, Year, everything()) %>%
  select(1,2, 135:145) %>%
  arrange(Year)
```
It does, generally appear that samples EITHER provide data on individual PCBs or
on co-eluted PCBs.  But interestingly, almost all samples indicate to the same
`TEST METHOD`, E1613, or E1613A.  There is no obvious pattern with respect to 
when the sample was collected.

We are unlikely to be able to resolve this discrepancy "after the fact".  We
next turn to looking at the PCB totals reported in the ata

# When Does Each Total Exist?
We look  narrowly at WET weights and totals that treat non-detects as zero.
We make the assumption for now that the lessons learned from that subset apply 
to the related data.
```{r}
SWAT_simplified %>%
  select(Code, ANALYSIS_LAB_SAMPLE_ID, `TEST METHOD`, `WEIGHT BASIS`,
         PARAMETER, CONCENTRATION) %>%
  filter (`WEIGHT BASIS` == 'WET') %>%
  filter(grepl("PCB", PARAMETER)) %>%
  filter(grepl("TOTAL", PARAMETER) |
           grepl('TEQ', PARAMETER) |
           grepl('CALCULATED', `TEST METHOD`)) %>%
  pivot_wider(names_from = PARAMETER, values_from = CONCENTRATION)
  
```

We appear to have THREE different types of totals:

1.  PCB TOTAL TEQ  
2.  TOTAL PCB  
3.  PCBs  

*  Groups 1 and 2 co-occur sometimes, but not always.
*  Group 3 appears to always occur with Group 1, and never with Group 2.
*  Groups 2 and 3 appear disjoint.

None of these make it obvious which PCBs were included in the sum to calculate
"totals".  
