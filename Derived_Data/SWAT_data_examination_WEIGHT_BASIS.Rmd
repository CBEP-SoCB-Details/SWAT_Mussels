---
title: "Review of Maine DEP EGAD Mussel Tissue Toxics Data Weight Basis"
subtitle: "Check that Weight BAsis data are Consistent"
author: "Curtis C. Bohlen, Casco Bay Estuary Partnership"
date: "9/10/2020"
output:
  github_document:
    toc: true
    toc_depth: 2
    fig_width: 7
    fig_height: 5
---

<img
  src="https://www.cascobayestuary.org/wp-content/uploads/2014/04/logo_sm.jpg"
  style="position:absolute;top:10px;right:50px;" />


# Introduction
Maine's Department of Environmental Protection (DEP) maintains a large database
of environmental data called "EGAD".  Citizens can request data from the
database through DEP staff.

CBEP requested data from DEP on levels of toxic contaminants in shellfish
tissue samples from Casco Bay. The result is a large (> 100,000 line) excel
spreadsheet containing data from about 40 sampling dates from 20 locations, over
a period of more than 15 years.

Unfortunately, the data delivery contains little metadata, so it takes some
effort to understand the data format and analyze it correctly. Among other
problems, we need to understand dates and locations of samples, what analytes
were used for different samples, etc.

In this notebook and accompanying notebooks, we take various slices through the
data to understand its structure.

sample_spatial.csv
sites_spatial.csv
Parameter List.csv

While those data sets ARE produced in this notebook, WE plan to produce a
simpler version that skips all the data exploraiton.

# Load Libraries
```{r load_libraries}
library(tidyverse)
library(readxl)
library(htmltools)  # used by knitr called here only to avoid startup text later in document
library(knitr)

library(CBEPgraphics)
load_cbep_fonts()
theme_set

library(LCensMeans)
```
# Load Data
## Establish Folder Reference
```{r folder_refs}
sibfldnm <- 'Original_Data'
parent   <- dirname(getwd())
sibling  <- file.path(parent,sibfldnm)
fn <- 'CascoBaySWATtissue_Bohlen.xlsx'
```

## Copy Data
This is a larger data file that takes some time to load.  Getting the column
types right dramatically improves load speed. Much of the data is qualitative,
and can't be handled in R.
```{r}
SWAT_data <- read_excel(file.path(sibling, fn), 
    sheet = "Mussels Data", col_types = c("numeric", 
        "text", "text", "text", "text", "text", 
        "text", "text", "text", "text", "text", 
        "text", "date", "text", "text", 
        "text", "date", "text", "numeric", 
        "text", "text", "text", "text", 
        "text", "numeric", "numeric", "text", 
        "text", "text", "text", "text", 
        "text", "numeric", "text", 
        "text", "text", "text", "text", 
        "text", "text", "text"))

before <- nrow(SWAT_data)
```

## Remove duplicates
Many samples -- nearly 20% -- are members of a group of duplicates.  We can
think of no valid reason why two records should be exact duplicates in this
setting, so we remove all duplicates using the unique() function.

## How many duplicates?
Let's generate a data subset including all complete duplicates, and evaluate its
size.
```{r}
dups <- SWAT_data[duplicated(SWAT_data),]
cat(round(nrow(dups)/nrow(SWAT_data) * 100,1))
cat(" percent of observations are duplicates.")
rm(dups)
```

## Remove all Complete Duplicate Data Rows
```{r}
SWAT_data <- unique(SWAT_data)
```

```{r}
(after <- nrow(SWAT_data))
cat('We retained ')
cat (round(after/before,3)*100)
cat ( ' percent of rows in the original data.')
```

# Checking values based on Wet WEight, Dry Weight, and Lipid Weight
## Check that (value of LIP <= DRY <= WET)
```{r}
SWAT_simplified %>%
  select(code, PARAMETER, `WEIGHT BASIS`, CONCENTRATION) %>%
  group_by(PARAMETER) %>%
  summarize(nlip = sum(`WEIGHT BASIS` == 'LIP', na.rm= TRUE),
            ndry = sum(`WEIGHT BASIS` == 'DRY', na.rm= TRUE),
            nwet = sum(`WEIGHT BASIS` == 'WET', na.rm= TRUE),
            problem = ! (nlip<= ndry & ndry <= nwet),
            .groups = 'drop') %>%
    filter(problem)
            
```
Two of those appear to be labeling problems, since the parameters apply to whole samples (e.g., percentage of lipids).
It's not clear what is going on with Mercury.

## Check that (value of LIP <= DRY <= WET)
```{r}
SWAT_simplified %>%
  select(code, PARAMETER, `WEIGHT BASIS`, CONCENTRATION) %>%
  group_by(code, PARAMETER) %>%
  summarize(nlip = sum(`WEIGHT BASIS` == 'LIP', na.rm= TRUE),
            ndry = sum(`WEIGHT BASIS` == 'DRY', na.rm= TRUE),
            nwet = sum(`WEIGHT BASIS` == 'WET', na.rm= TRUE),
            vlip = mean(CONCENTRATION[`WEIGHT BASIS` == 'LIP'], na.rm= TRUE),
            vdry = mean(CONCENTRATION[`WEIGHT BASIS` == 'DRY'], na.rm= TRUE),
            vwet = mean(CONCENTRATION[`WEIGHT BASIS` == 'WET'], na.rm= TRUE),
            problem = ! (vlip >= vdry & vdry >= vwet),
            .groups = 'drop') %>%
      filter(problem)
```
The last six problems are all Moisture values

These are all PCB values, all from one site, and all with an apparent TWO 
sample values for each parameters.all PCBs where the apparent sample size is two.
